{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Inverse Reinforcement Learning\n",
    "\n",
    "The code in this notebook is based on the Maximum Entropy Inverse Reinforcement Learning paper by Ziebart et al. (2008).\n",
    "\n",
    "_Disclaimer:_\n",
    "The code provided in this notebook is written for readability.\n",
    "In some sections, this has a considerable impact on performance:\n",
    "Many operations, especially the ones involving the transition probability $P(s_k \\mid s_i, a_j)$, can be reformulated as a combination or series of matrix multiplications. For an implementation considering these optimizations have a look at the accompanying python files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "While I assume some familiarity with the basics of reinforcement and inverse reinforcement learning, here's a short overview (so feel free to skip this part if you already know them):\n",
    "In both settings, we describe our world using a Markov decision process (MDP).\n",
    "A MDP is a 5-tuple $(S, A, T, r, \\gamma)$ with states $S$, actions $A$, transition model $T(s_t, a_t, s_{t+1}) = p(s_{t+1} \\mid s_t, a_t)$, reward function $r(s_t, a_t, s_{t+1}) \\in \\mathbb{R}$, and reward discount factor $\\gamma \\in [0, 1]$ decreasing the reward over time (where $a_t \\in A$ and $s_t, s_{t+1} \\in S$).\n",
    "In the inverse reinforcement learning setting we will only use per-state rewards $r(s) \\in \\mathbb{R}$.\n",
    "The key part of an MDP is that any action only relies on the current state, meaning complete independence of all of the preceding history.\n",
    "\n",
    "The goal of reinforcement learning (RL) is to find an optimal sequence of actions, i.e. a policy describing the optimal action per state, for an autonomous agent given a reward signal $r$.\n",
    "The reward signal provides feedback to the agent, affirming its behavior on actions that help further the goal of the task at hand, and punishing it on actions that are counter-productive to this goal.\n",
    "Policies come in two flavors: deterministic and stochastic.\n",
    "Deterministic policies are defined as function $\\pi: S \\to A$, whereas stochastic policies are defined as probability distributions over actions, i.e. $\\pi(a \\mid s)$.\n",
    "While in the usual RL setting the (or at least one) optimal policy is guaranteed to be deterministic, in inverse reinforcement learning (and not only there), it also makes sense to talk about stochastic policies.\n",
    "\n",
    "Inverse reinforcement learning (IRL), as the name states, does exactly the inverse of RL.\n",
    "Given demonstrations of an expert (agent), consisting of trajectories $\\tau = \\left( (s_0, a_0), (s_1, a_1), \\ldots, (s_{n-1}, a_{n-1}), s_n \\right)$ through the state-action space, IRL aims to recover the underlying reward function which explains the behavior of the expert.\n",
    "\n",
    "To allow for computation with states, we use so-called features.\n",
    "Features are, in this case, defined as a function $\\phi: S \\to \\mathbb{R}^d$, mapping states to $d$-dimensional vectors, and can be arbitrarily chosen.\n",
    "In general, we assume that $\\phi(\\tau) = \\sum_{t = 0}^{|\\tau|} \\phi(s_t)$ where $|\\tau|$ denotes the length of the trajectories (visited states), i.e. that the features of a trajectory $\\tau$ are the sum of the features of the states visited by this trajectory, counting repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Principle of Maximum Entropy\n",
    "\n",
    "The general idea of Maximum Entropy Inverse Reinforcement Learning is based on feature-expectation matching [\\[Abbel & Ng 2004\\]](#References):\n",
    "The expected visitation-frequency of features in the demonstrations provided by the expert should equal the exected visitation-frequency of features visited by the agent following the recovered reward function.\n",
    "In other words: The features describing the states of our world should be, in expectance, visited equally often by the agent following our recovered reward function and by the expert demonstrating (nearly) optimal behavior.\n",
    "In equations, we can express this as the expectation of features $\\phi$ over trajectories $\\tau$ derived from the reward we want to recover, and \n",
    "\n",
    "\\\\[\n",
    "    \\mathbb{E}_{\\pi^L}[\\phi(\\tau)] = \\mathbb{E}_{\\pi^E}[\\phi(\\tau)],\n",
    "\\\\]\n",
    "\n",
    "where the learner follows a policy $\\pi^L$ directly implied by the reward.\n",
    "The expert follows an implicit policy $\\pi^E$ that encodes its notion of reward and optimality.\n",
    "Note that we can also express the expected feature visitation frequency as sum over trajectories\n",
    "\n",
    "\\\\[\n",
    "    \\mathbb{E}_{\\pi^L}[\\phi(\\tau)] = \\sum_{\\tau} p_{\\pi^L}(\\tau) \\phi(\\tau)\n",
    "\\\\]\n",
    "\n",
    "with the probability distribution $p_{\\pi^L}(\\tau)$ of trajectories of the learner. Finding such a match, however, is not a well-posed problem in accordance to the definition by Hadamard: There is not the single one, but many possible solutions.\n",
    "Multiple reward functions can achieve the same expected feature-visitation frequency [\\[Ng et al. 99; Abbel & Ng 2004; Ziebart 2010\\]](#References).\n",
    "To resolve this ambiguity, Ziebart et al. [\\[Ziebart et al. 2008\\]](#References). propose to choose the solution (i.e. the $p_{\\pi^L}$) maximizing the entropy.\n",
    "\n",
    "But why should we maximize the entropy?\n",
    "To answer this, we have to understand what entropy represents.\n",
    "First of all, the entropy $H(p)$ of some event probability distribution $p$ is defined as\n",
    "\n",
    "\\\\[\n",
    "    H(p)\n",
    "    = -\\sum_{x \\in \\mathcal{X}} p(x) \\log_2 p(x)\n",
    "    = \\sum_{x \\in \\mathcal{X}} p(x) \\cdot \\log_2 \\frac{1}{p(x)},\n",
    "\\\\]\n",
    "\n",
    "where $X$ is the set containing all events $x$ and $p(x)$ the probability of event $x$ occurring.\n",
    "Let us now assume that we want to communicate the occurrence of all events $x$ with some other party in an efficient manner.\n",
    "To do this, we want to minimize the expected message length, so messages that will be sent frequently should be short, and messages that will be sent almost never are allowed to be long.\n",
    "Following this trail of thought leads to the term $h(x) = \\log_2(1/p(x))$, which is the optimal number of bits that we should spend on the message representing event $x$.\n",
    "With lower probability $p(x)$, the term $\\log_2(1/p(x))$ increases.\n",
    "In fact it increases logarithmically, as with more bits available, we can encode exponentially more events.\n",
    "Using this observation for the entropy $H$ then yields nothing more than the entropy being the lower limit of the expected message length over all messages, i.e.:\n",
    "\n",
    "\\\\[\n",
    "    H(p)\n",
    "    = \\mathbb{E}_{p(x)}\\left[h(x)\\right].\n",
    "\\\\]\n",
    "\n",
    "Note that this is in fact the underlying principle of Huffman coding (which, due to this relation, is guaranteed to be optimal9.\n",
    "As is done generally, we instead of the logarithm to base two use the normal logarithm.\n",
    "Since $\\log_2(x) = \\log(x)/\\log(2)$ holds, we are only dropping a constant factor of $\\log(2)$ which does not impact extremas or our reasoning below, and simplifies further computations.\n",
    "\n",
    "With that in mind, let us ask again:\n",
    "Why should we maximize the entropy?\n",
    "Now we can give a simple reasoning [\\[Jaynes 1957\\]](#References):\n",
    "Let us assume that we have two distributions, $p_1$ and $p_2$, with entropies $H(p_1) > H(p_2)$.\n",
    "From our previous observations, we know now that to encode messages from $p_1$ we, in expectancy, need more bits than to encode messages from $p_2$.\n",
    "This is the key point, because this in turn also means that we have less information about $p_1$ than about $p_2$.\n",
    "If we know more about a distribution, we need less bits to encode events from it.\n",
    "If we know everything, we do not need to send/encode anything, and if we know nothing, we need to send everything.\n",
    "\n",
    "But isn't it good if we know more? The less entropy the better, right? you may ask.\n",
    "No.\n",
    "Not for many optimization problems:\n",
    "Consider a problem, like feature-expectation matching, which has many solutions fullfilling our constraints.\n",
    "The only information which we give our solver for this problem is the feature-expectations we want to replicate.\n",
    "All solutions provided by our solver contain this information.\n",
    "Yet they most certainly have a different entropy values.\n",
    "This must mean that (at least) some solutions have additional information that we did not provide, i.e. they have a bias.\n",
    "By choosing the solution with maximum entropy, we choose the solution with minimal information.\n",
    "Note that all solutions already satisfy our constraints, thus we actually choose the solution that fits our information with a minimal bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy Inverse Reinforcement Learning\n",
    "\n",
    "Applying our findings from the previous section to feature-expectation matching directly results in a constrained optimization problem:\n",
    "\n",
    "\\\\[\\DeclareMathOperator{\\argmax}{arg\\,max}\n",
    "\\begin{alignat*}{2}\n",
    "    \\argmax_p\\quad\n",
    "        && H(p) \\\\\n",
    "    \\text{subject to}\\quad\n",
    "        && \\mathbb{E}_{\\pi^L}[\\phi(\\tau)] &= \\mathbb{E}_{\\pi^E}[\\phi(\\tau)],\n",
    "            \\tag{feature-expectation matching} \\\\\n",
    "        && \\sum_{\\tau} p(\\tau) = 1, &\\quad \\forall \\tau : p(\\tau) &> 0\n",
    "            \\tag{probability constraints}\n",
    "\\end{alignat*}\n",
    "\\\\]\n",
    "\n",
    "This problem expresses that we want to find a probability distribution $p(\\tau)$ over trajectories $\\tau$ with maximum entropy, under which the expected feature visitation frequencies of learner $\\mathbb{E}_{\\pi^L}[\\phi(\\tau)]$ and expert $\\mathbb{E}_{\\pi^E}[\\phi(\\tau)]$ match (that $\\phi(\\tau)$ represents the features visited by trajectory $\\tau$).\n",
    "Note that the policy $\\pi^L$ of the learner depends on the probability distribution $p(\\tau)$:\n",
    "\\\\[\n",
    "    \\pi^L(a \\mid s) \\propto \\sum_{\\tau : (s, a) \\in \\tau} p(\\tau),\n",
    "    \\tag{1}\n",
    "\\\\]\n",
    "i.e. the policy of the learner is proportional to the sum of the probabilities of all trajectories performing action $a$ in state $s$.\n",
    "\n",
    "Now we have the probability distribution over trajectories, but how does this help us to recover the reward function $R: S \\to \\mathbb{R}$?\n",
    "Following the school of basic reinforcement learning provides us with the answer: The reward dictates the policy, which in turn dictates the trajectory distribution $p(\\tau)$.\n",
    "A key assumption of Maximum Entropy IRL is that we know the behavior of our MDP, i.e. we have a perfect model representing the transition probabilities $p(s_{t+1} \\mid s_t, a_t)$, so the only thing we actually need to learn is the reward.\n",
    "Everything else either is derived from it or assumed known.\n",
    "To be able to learn the reward, we need to parameterize it.\n",
    "For this we assume linearity with regards to features, i.e.\n",
    "\n",
    "\\\\[\n",
    "    R(\\tau) = \\omega^\\top \\phi(\\tau)\n",
    "\\\\]\n",
    "\n",
    "with $\\omega \\in \\mathbb{R}^d$ being the reward parameter vector.\n",
    "To make this dependency on the reward parameters explicit, we write $p(\\tau \\mid \\omega)$ (and $\\pi(a \\mid s, \\omega)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution and Partition Function\n",
    "\n",
    "Solving the above mathematical program for MDPs with deterministic transition dynamics (i.e. MDPs where all actions have predetermined deterministic outcomes) using the method of Lagrange multipliers leads to the observation that\n",
    "\n",
    "\\\\[\n",
    "    p_d(\\tau \\mid \\omega) = \\frac{1}{Z(\\omega)} \\exp \\left( \\omega^\\top \\phi(\\tau) \\right),\n",
    "    \\qquad\n",
    "    Z(\\omega) = \\sum_{\\tau} \\exp \\left( \\omega^\\top \\phi(\\tau) \\right)\n",
    "\\\\]\n",
    "\n",
    "with the so-called partition function $Z(\\omega)$ simply normalizing the values to fullfill the probability distribution constraint [\\[Ziebart et al. 2008; Osa et al. 2018\\]](#References).\n",
    "By choosing the reward to linearly depend on the features, we have also ensured that the Lagrange multipliers are exactly the reward parameters $\\omega$ [\\[Osa et al. 2018\\]](#References).\n",
    "For MDPs with stochastic transitions, Ziebart et al. [\\[Ziebart et al. 2008\\]](#References) propose to modify the deterministic solution yielding the approximation\n",
    "\n",
    "\\\\[\n",
    "    p_s(\\tau \\mid \\omega)\n",
    "    \\approx\n",
    "        \\frac{1}{Z(\\omega)} \\exp\\left( \\omega^\\top \\phi(\\tau) \\right)\n",
    "        \\prod_{s_{t+1}, a_t, s_t \\in \\tau} p(s_{t+1} \\mid s_t, a_t).\n",
    "    \\tag{2}\n",
    "\\\\]\n",
    "\n",
    "Note that we're simply multiplying the deterministic solution with combined transition probability of the trajectory.\n",
    "As a result of said modification, however, we introduce a bias to the reward function [\\[Osa et al. 2018\\]](#References).\n",
    "To avoid this, Ziebart [\\[Ziebart 2010\\]](#References) proposes the Maximum Causal Entropy IRL method in his thesis.\n",
    "In the scope of this notebook, we'll stick to the normal (non-causal) entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "We now know the parameterized form of the distribution, so how can we optimize the parameters?\n",
    "The answer is fairly straightforward: We maximize the log-likelihood over all demonstrated trajectories $D = \\{\\tau_i\\}_{i=1}^{N}$, i.e.\n",
    "\n",
    "\\\\[\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "    \\omega^* = \\argmax_{\\omega} \\mathcal{L}(\\omega) = \\argmax_{\\omega} \\sum_{\\tau \\in D} \\log p(\\tau \\mid \\omega),\n",
    "\\\\]\n",
    "\n",
    "using gradient ascent.\n",
    "A small side-note: Maximizing the log-likelihood is equivalent to minimizing the Kullback-Leibler divergence $D_{KL}(p^E(\\tau) \\,\\|\\, p(\\tau \\mid \\omega))$ [\\[Bishop 2006\\]](#References), so it can also be interpreted as the M-projection onto the manifold of the maximum entropy distribution [\\[Osa et al. 2018\\]](#References).\n",
    "The (averaged) gradient is then simply the difference between expected empirical feature counts $\\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right]$ and the learners expected feature counts (derived from the trajectory probabilities $p(\\tau \\mid \\omega)$), i.e. (Equation (3a))\n",
    "\n",
    "\\\\[\\begin{align*}\n",
    "    \\nabla_\\omega \\mathcal{L}(\\omega)\n",
    "    &= \\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right] - \\sum_{\\tau} p(\\tau \\mid \\omega)\\ \\phi(\\tau)\n",
    "        \\tag{3a}\\\\\n",
    "    &= \\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right] - \\sum_{s_i} D_{s_i} \\phi(s_i),\n",
    "        \\tag{3b}\\\\\n",
    "\\end{align*}\\\\]\n",
    "\n",
    "which we can express in terms of the state-visitation frequency $D_{s_i}$ (Equation (3b)), assuming $\\phi(\\tau) = \\sum_{t = 0}^{|\\tau|} \\phi(s_t)$ [\\[Ziebart et al. 2008\\]](#References).\n",
    "Note that (due to the log-likelihood) this gradient holds for both deterministic and stochastic transition dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the State-Visitation Frequency\n",
    "\n",
    "Now, we have only one remaining question:\n",
    "How do we compute the state-visitation frequency $D_{s_i}$?\n",
    "Following good computer-science fashion, we divide and conquer:\n",
    "First, we compute a (stochastic) policy $\\pi(a \\mid s, \\omega)$ (referred to as the local action probability) with a backward pass, after which we compute the state-visitation frequency under this policy with a simple forward pass.\n",
    "While the second part is fairly straightforward (as will become apparent by the code below), the first certainly benefits of a small explanation.\n",
    "\n",
    "The basic idea of the first pass is to remember our earlier observation about the learner policy $\\pi^L(a \\mid s)$ (Equation (1)), and then recursively expand this using the solution we derived for our trajectory distribution $p(\\tau \\mid \\omega)$ (Equation (2)) until we are not reasoning about full or partial trajectories any more, but the individual state transitions.\n",
    "This then yields the set of equations [\\[Ziebart et al. 2008\\]](#References)\n",
    "\n",
    "\\\\[\n",
    "    \\pi(a_j \\mid s_i, \\omega) = \\frac{Z_{s_i, a_j}}{Z_{s_j}}\n",
    "    ,\\quad\n",
    "    Z_{s_i, a_j} = \\sum_{k} p(s_k \\mid s_i, a_j)\\, \\exp \\left(\\omega^\\top \\phi(s_i)\\right)\\, Z_{s_k}\n",
    "    ,\\quad\n",
    "    Z_{s_i} = \\sum_{a_j} Z_{s_i, a_j}.\n",
    "\\\\]\n",
    "\n",
    "Here, $Z_{s_i}$ represents the state-partition-function, again normalizing the probabilities, and $Z_{s_i, a_i}$ is referred to as the state-action partition function.\n",
    "Setting the state-partition function $Z_{s_i} = 1$ for terminal states and then recursively backing up, using the equations for $Z_{s_i}$ and $Z_{s_i, a_j}$, from those states yields a set of values that we can then use to compute the local action probabilities following the above equation.\n",
    "\n",
    "This backup-pass somewhat resembles a value-iteration scheme to solve an MDP.\n",
    "It turns out that this backup part of the algorithm is the only thing that differs between Maximum Entropy and Maximum Causal Entropy IRL.\n",
    "In fact, for the Maximum Causal Entropy approach, one can show that the partition functions are an analogy of the Bellman equation, the so-called soft Bellman equation, which allows for a straightforward extension of the value-iteration algorithm to this problem [\\[Ziebart 2010\\]](#References).\n",
    "\n",
    "This concludes the prequisites we need to know for our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Plan Forward\n",
    "\n",
    "Before we actually begin with the code, let's do a quick recap:\n",
    "First of all, we have some preparation to do.\n",
    "As prequisites, we need an MDP (a world) which we can use for demonstration (which also provides us with some features) and some trajectories provided by an expert (which we here simulate).\n",
    "We need to compute the feature-expectancy for the given trajectories, and inside our optimization loop we need to compute the expected state-visitation frequency, for which we also need the probability of states being starting-points (based on the trajectories), as well as perform a gradient-ascent optimization step.\n",
    "For most of the boilerplate code, specifically for the MDP, trajectory-generation, the actual optimization step, and plotting, we will re-use the code from the accompanying `src` directory.\n",
    "\n",
    "Now let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "First off, the imports: We need the usual external dependencies for calcualtion and plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from itertools import product               # Cartesian product for iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our framework to hide the boring stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow us to re-use the framework from the src directory\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "\n",
    "import gridworld as W                       # basic grid-world MDPs\n",
    "import trajectory as T                      # trajectory generation\n",
    "import optimizer as O                       # stochastic gradient descent optimizer\n",
    "import solver as S                          # MDP solver (value-iteration)\n",
    "import plot as P                            # helper-functions for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also use interactive javascript-based plots and pre-define a global style for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [9, 5]     # set default figure size\n",
    "style = {                                   # global style for plots\n",
    "    'border': {'color': 'red', 'linewidth': 0.5},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDP and Trajectories\n",
    "\n",
    "Now, let's create our MDP.\n",
    "We're using a square grid-world, i.e. a world with $5 \\times 5$ states where an agent can move to any of the four adjacent states.\n",
    "If the agent would move over an edge, it will stay in the same state, in any other case, the agent will always move to another state.\n",
    "To introduce stochastic transition dynamics, our agent has a $20\\%$ probability of \"slipping\", meaning that it will choose a random action instead of the one selected.\n",
    "Note that this is not a full MDP as defined above, we just need the main components, i.e. the states, actions, and transition model via the `world`, the reward (per state) and a list of terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mdp():\n",
    "    # create our world\n",
    "    world = W.IcyGridWorld(size=5, p_slip=0.2)\n",
    "\n",
    "    # set up the reward function\n",
    "    reward = np.zeros(world.n_states)\n",
    "    reward[-1] = 1.0\n",
    "    reward[8] = 0.65\n",
    "\n",
    "    # set up terminal states\n",
    "    terminal = [24]\n",
    "\n",
    "    return world, reward, terminal\n",
    "\n",
    "# set-up the GridWorld Markov Decision Process\n",
    "world, reward, terminal = setup_mdp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need some trajectories from which we can learn.\n",
    "Normally, they would be provided by experts, but here we will simulate them using a stochastic policy derived via standard value iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expert_trajectories(world, reward, terminal):\n",
    "    n_trajectories = 200         # the number of \"expert\" trajectories\n",
    "    discount = 0.9               # discount for constructing an \"expert\" policy\n",
    "    weighting = lambda x: x**50  # down-weight less optimal actions\n",
    "    start = [0]                  # starting states for the expert\n",
    "\n",
    "    # compute the value-function\n",
    "    value = S.value_iteration(world.p_transition, reward, discount)\n",
    "    \n",
    "    # create our stochastic policy using the value function\n",
    "    policy = S.stochastic_policy_from_value(world, value, w=weighting)\n",
    "    \n",
    "    # a function that executes our stochastic policy by choosing actions according to it\n",
    "    policy_exec = T.stochastic_policy_adapter(policy)\n",
    "    \n",
    "    # generate trajectories\n",
    "    tjs = list(T.generate_trajectories(n_trajectories, world, policy_exec, start, terminal))\n",
    "    \n",
    "    return tjs, policy\n",
    "\n",
    "# generate some \"expert\" trajectories (and its policy for visualization)\n",
    "trajectories, expert_policy = generate_expert_trajectories(world, reward, terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our world via the reward (left), expert policy (right) and trajectories (right, transparent white lines).\n",
    "The terminal state is the upper-right state, the initial state for the trajectories is the lower-left state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='3ef727f2-1a51-4faf-b1b0-4fbfe8a5e141'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.title.set_text('Original Reward')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_state_values(ax, world, reward, **style)\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.title.set_text('Expert Policy and Trajectories')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_stochastic_policy(ax, world, expert_policy, **style)\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "for t in trajectories:\n",
    "    P.plot_trajectory(ax, world, t, lw=5, color='white', alpha=0.025)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done, we have all the prequisites we need to run the actual algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Actual Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the easy parts:\n",
    "Remember that the gradient we need to compute for optimization is\n",
    "\n",
    "\\\\[\n",
    "    \\nabla_\\omega \\mathcal{L}(\\omega)\n",
    "    = \\underbrace{\\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right]}_{(1)}\n",
    "        - \\underbrace{\\sum_{s_i} D_{s_i} \\phi(s_i)}_{(2)},\n",
    "\\\\]\n",
    "\n",
    "so we first need to get the feature expectation $\\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right]$ (part (1)) from the trajectories of our trainings-set $D$.\n",
    "This is fairly simple, as for each trajectory we just need to check which states are going to be visited, sum the features of these states up (counting repetitions), and then at the end average over all trajectories, i.e.\n",
    "\n",
    "\\\\[\n",
    "    \\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right]\n",
    "    = \\frac{1}{|D|} \\sum_{\\tau \\in D} \\sum_{s_t \\in \\tau} \\phi(s_t)\n",
    "\\\\]\n",
    "\n",
    "or as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_expectation_from_trajectories(features, trajectories):\n",
    "    n_states, n_features = features.shape\n",
    "\n",
    "    fe = np.zeros(n_features)\n",
    "\n",
    "    for t in trajectories:                  # for each trajectory\n",
    "        for s in t.states():                # for each state in trajectory\n",
    "            fe += features[s, :]            # sum-up features\n",
    "\n",
    "    return fe / len(trajectories)           # average over trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fairly simple thing we need to know about the trajectories is the probability of a state being a starting state.\n",
    "This is required for the state-visitation-frequency $D_{s_i}$ which we in turn need for part (2) of the gradient.\n",
    "Here, we just count the number of trajectories starting in each state and then normalize with the number of trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_probabilities_from_trajectories(n_states, trajectories):\n",
    "    p = np.zeros(n_states)\n",
    "\n",
    "    for t in trajectories:                  # for each trajectory\n",
    "        p[t.transitions()[0][0]] += 1.0     # increment starting state\n",
    "\n",
    "    return p / len(trajectories)            # normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we're ready to look at the algorithm computing the expected state visitation frequency (this is Algorithm 1 in the Maximum Entropy IRL paper by Ziebart et al. [\\[Ziebart et al. 2008\\]](#References)).\n",
    "As already mentioned above, this algorithm consists of two parts: A backward pass computing the local action probabilities $\\pi(a \\mid s, \\omega)$ and a forward pass computing the state visitation frequencies $D_{s_i}$ from those.\n",
    "\n",
    "For the **backward-pass** we recursively back-up from terminal states (initialized with $Z_{s_i} = 1$), computing the state and state-action partition functions $Z_{s_i}$ and $Z_{s_i, a_j}$.\n",
    "When we have those, we can compute the local action probability using $\\pi(a_j \\mid s_i, \\omega)$.\n",
    "A technical issue we stumble accross here, is that this process does not converge.\n",
    "To this end, we choose to run $2 \\cdot |S|$ iterations, as this ensures the maximum trajectory length is covered ($|S|$) and we have some slack.\n",
    "As explained previously, the equations we need for this are\n",
    "\n",
    "\\\\[\n",
    "    \\pi(a_j \\mid s_i, \\omega) = \\frac{Z_{s_i, a_j}}{Z_{s_j}}\n",
    "    ,\\quad\n",
    "    Z_{s_i, a_j} = \\sum_{k} p(s_k \\mid s_i, a_j)\\, \\exp \\left(\\omega^\\top \\phi(s_i)\\right)\\, Z_{s_k}\n",
    "    ,\\quad\n",
    "    Z_{s_i} = \\sum_{a_j} Z_{s_i, a_j}.\n",
    "\\\\]\n",
    "\n",
    "For the **forward-pass** we initialize the state-visitation frequency with the probability of a state being a starting-point (`p_initial`).\n",
    "To compute the state-visitation-frequency for another state, we just sum up the transition probabilities of (direct) transitions to this other state multiplied by the state-visitation frequency of the origin-state of this transition, resulting in a forward-propagation of state-visitation frequencies.\n",
    "Also, we only consider transitions originating in non-terminal states.\n",
    "Expressed as formula, we iteratively compute\n",
    "\n",
    "\\\\[\n",
    "    D_{s_k, t + 1}\n",
    "    = \\sum_{s_i \\in S_{\\text{nt}}} \\sum_{a_j \\in A} D_{s_i, t} \\; \\pi(a_j \\mid s_i) \\; p(s_k \\mid s_i, a_j)\n",
    "\\\\]\n",
    "\n",
    "and then sum this up over all time-steps $t$ for the final result.\n",
    "Again, we run $2 \\cdot |S|$ iterations, altough this algorithm can also be modified for convergence (see `expected_svf_from_policy(...)` in the accompanying code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_svf(p_transition, p_initial, terminal, reward, eps=1e-5):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    nonterminal = set(range(n_states)) - set(terminal)  # nonterminal states\n",
    "    \n",
    "    # Backward Pass\n",
    "    # 1. initialize at terminal states\n",
    "    zs = np.zeros(n_states)                             # zs: state partition function\n",
    "    zs[terminal] = 1.0\n",
    "\n",
    "    # 2. perform backward pass\n",
    "    for _ in range(2 * n_states):                       # longest trajectory: n_states\n",
    "        # reset action values to zero\n",
    "        za = np.zeros((n_states, n_actions))            # za: action partition function\n",
    "\n",
    "        # for each state-action pair\n",
    "        for s_from, a in product(range(n_states), range(n_actions)):\n",
    "\n",
    "            # sum over s_to\n",
    "            for s_to in range(n_states):\n",
    "                za[s_from, a] += p_transition[s_from, s_to, a] * np.exp(reward[s_from]) * zs[s_to]\n",
    "        \n",
    "        # sum over all actions\n",
    "        zs = za.sum(axis=1)\n",
    "\n",
    "    # 3. compute local action probabilities\n",
    "    p_action = za / zs[:, None]\n",
    "\n",
    "    # Forward Pass\n",
    "    # 4. initialize with starting probability\n",
    "    d = np.zeros((n_states, 2 * n_states))              # d: state-visitation frequencies\n",
    "    d[:, 0] = p_initial\n",
    "\n",
    "    # 5. iterate for N steps\n",
    "    for t in range(1, 2 * n_states):                    # longest trajectory: n_states\n",
    "        \n",
    "        # for all states\n",
    "        for s_to in range(n_states):\n",
    "            \n",
    "            # sum over nonterminal state-action pairs\n",
    "            for s_from, a in product(nonterminal, range(n_actions)):\n",
    "                d[s_to, t] += d[s_from, t-1] * p_action[s_from, a] * p_transition[s_from, s_to, a]\n",
    "\n",
    "    # 6. sum-up frequencies\n",
    "    return d.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the core algorithm:\n",
    "First, we compute the feature expectation $\\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right]$ and starting-state probabilities using the functions defined above.\n",
    "Those are static, so we only need to compute them once before we start optimizing.\n",
    "After this, we initialize our parameters $\\omega$ and then iteratively perform optimization-steps until convergence is reached.\n",
    "For each optimization-step, we compute the gradient\n",
    "\n",
    "\\\\[\n",
    "    \\nabla_\\omega \\mathcal{L}(\\omega)\n",
    "    = \\mathbb{E}_{\\pi^E} \\left[ \\phi(\\tau) \\right] - \\sum_{s_i} D_{s_i} \\phi(s_i),\n",
    "\\\\]\n",
    "\n",
    "using the function above to get the expected state-visitation frequency $D_{s_i}$ from our current recovered reward $r(s_i) = \\omega^\\top \\phi(s_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxent_irl(p_transition, features, terminal, trajectories, optim, init, eps=1e-4):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    _, n_features = features.shape\n",
    "\n",
    "    # compute feature expectation from trajectories\n",
    "    e_features = feature_expectation_from_trajectories(features, trajectories)\n",
    "    \n",
    "    # compute starting-state probabilities from trajectories\n",
    "    p_initial = initial_probabilities_from_trajectories(n_states, trajectories)\n",
    "\n",
    "    # gradient descent optimization\n",
    "    omega = init(n_features)        # initialize our parameters\n",
    "    delta = np.inf                  # initialize delta for convergence check\n",
    "\n",
    "    optim.reset(omega)              # re-start optimizer\n",
    "    while delta > eps:              # iterate until convergence\n",
    "        omega_old = omega.copy()\n",
    "\n",
    "        # compute per-state reward from features\n",
    "        reward = features.dot(omega)\n",
    "\n",
    "        # compute gradient of the log-likelihood\n",
    "        e_svf = compute_expected_svf(p_transition, p_initial, terminal, reward)\n",
    "        grad = e_features - features.T.dot(e_svf)\n",
    "\n",
    "        # perform optimization step and compute delta for convergence\n",
    "        optim.step(grad)\n",
    "        \n",
    "        # re-compute detla for convergence check\n",
    "        delta = np.max(np.abs(omega_old - omega))\n",
    "\n",
    "    # re-compute per-state reward and return\n",
    "    return features.dot(omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've defined everything we need, so we can now finally run the algorithm.\n",
    "For that, we first get our feature-mapping: We're using one-hot vectors here, so our features are a set of orthogonal vectors, one per state.\n",
    "We select an initialization strategy for our parameters:, specifically we just set them all to one, and we choose exponentiated stochastic gradient ascent an optimizer.\n",
    "All of those parameters can, of course, be tuned and adapted to the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up features: we use one feature vector per state\n",
    "features = W.state_features(world)\n",
    "\n",
    "# choose our parameter initialization strategy:\n",
    "#   initialize parameters with constant\n",
    "init = O.Constant(1.0)\n",
    "\n",
    "# choose our optimization strategy:\n",
    "#   we select exponentiated stochastic gradient descent with linear learning-rate decay\n",
    "optim = O.ExpSga(lr=O.linear_decay(lr0=0.2))\n",
    "\n",
    "# actually do some inverse reinforcement learning\n",
    "reward_maxent = maxent_irl(world.p_transition, features, terminal, trajectories, optim, init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our results and compare them to the original reward.\n",
    "Also show the optimal policies derived from both reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='a68a5d65-719b-4158-ba6f-dd8b66b5e473'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.title.set_text('Original Reward')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_state_values(ax, world, reward, **style)\n",
    "P.plot_deterministic_policy(ax, world, S.optimal_policy(world, reward, 0.8), color='red')\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.title.set_text('Recovered Reward')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_state_values(ax, world, reward_maxent, **style)\n",
    "P.plot_deterministic_policy(ax, world, S.optimal_policy(world, reward_maxent, 0.8), color='red')\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the feature-expectation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: this code will only work with one feature per state\n",
    "p_initial = initial_probabilities_from_trajectories(world.n_states, trajectories)\n",
    "e_svf = compute_expected_svf(world.p_transition, p_initial, terminal, reward_maxent)\n",
    "e_features = feature_expectation_from_trajectories(features, trajectories)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.title.set_text('Trajectory Feature Expectation')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_state_values(ax, world, e_features, **style)\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.title.set_text('MaxEnt Feature Expectation')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "p = P.plot_state_values(ax, world, features.T.dot(e_svf), **style)\n",
    "fig.colorbar(p, cax=cax)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- \\[Abbel & Ng 2004\\]: https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf\n",
    "- \\[Bishop 2006\\]: https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\n",
    "- \\[Jaynes 1957\\]: https://bayes.wustl.edu/etj/articles/theory.1.pdf\n",
    "- \\[Ng et al. 99\\]: https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/NgHaradaRussell-shaping-ICML1999.pdf\n",
    "- \\[Osa et al. 2018\\]: https://arxiv.org/abs/1811.06711\n",
    "- \\[Ziebart et al. 2008\\]: https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf\n",
    "- \\[Ziebart 2010\\]: https://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
